{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import cifar100, cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: x=(50000, 32, 32, 3), y=(50000, 10)\n",
      "Test: x=(10000, 32, 32, 3), y=(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Now import Cifar-10 data and process it.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print('Train: x=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: x=%s, y=%s' % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprocessed\n",
      "Train: x=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test: x=(10000, 32, 32, 3), y=(10000, 1)\n",
      "\n",
      "Processed\n",
      "Train: x=(50000, 32, 32, 3), y=(50000, 100)\n",
      "Test: x=(10000, 32, 32, 3), y=(10000, 100)\n"
     ]
    }
   ],
   "source": [
    "# Now import Cifar-100 data and process it.\n",
    "(x100_train, y100_train), (x100_test, y100_test ) = cifar100.load_data()\n",
    "print('Unprocessed')\n",
    "print('Train: x=%s, y=%s' % (x100_train.shape, y100_train.shape))\n",
    "print('Test: x=%s, y=%s' % (x100_test.shape, y100_test.shape))\n",
    "print('')\n",
    "\n",
    "# Fill in the rest.\n",
    "#x100_train = x100_train.reshape(50000, 3072)\n",
    "#x100_test = x100_test.reshape(10000, 3072)\n",
    "x100_train = x100_train.astype('float32')\n",
    "x100_test = x100_test.astype('float32')\n",
    "x100_train /= 255\n",
    "x100_test /= 255\n",
    "\n",
    "y100_train = tf.keras.utils.to_categorical(y100_train, 100)\n",
    "y100_test = tf.keras.utils.to_categorical(y100_test, 100)\n",
    "\n",
    "print('Processed')\n",
    "print('Train: x=%s, y=%s' % (x100_train.shape, y100_train.shape))\n",
    "print('Test: x=%s, y=%s' % (x100_test.shape, y100_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 209,802\n",
      "Trainable params: 209,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 92s 2ms/sample - loss: 1.8674 - accuracy: 0.3206 - val_loss: 1.9632 - val_accuracy: 0.3084\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 5s 99us/sample - loss: 1.6738 - accuracy: 0.3990 - val_loss: 1.6405 - val_accuracy: 0.4154\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 4s 85us/sample - loss: 1.5991 - accuracy: 0.4264 - val_loss: 1.6238 - val_accuracy: 0.4237\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 4s 86us/sample - loss: 1.5505 - accuracy: 0.4430 - val_loss: 1.6148 - val_accuracy: 0.4195\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 1.5151 - accuracy: 0.4549 - val_loss: 1.5223 - val_accuracy: 0.4540\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 4s 74us/sample - loss: 1.4856 - accuracy: 0.4697 - val_loss: 1.5251 - val_accuracy: 0.4576\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 4s 73us/sample - loss: 1.4607 - accuracy: 0.4758 - val_loss: 1.5826 - val_accuracy: 0.4424\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 4s 73us/sample - loss: 1.4411 - accuracy: 0.4824 - val_loss: 1.4786 - val_accuracy: 0.4691\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 4s 73us/sample - loss: 1.4251 - accuracy: 0.4874 - val_loss: 1.6280 - val_accuracy: 0.4342\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 1.4080 - accuracy: 0.4944 - val_loss: 1.4890 - val_accuracy: 0.4705\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 4s 74us/sample - loss: 1.3956 - accuracy: 0.4994 - val_loss: 1.4921 - val_accuracy: 0.4734\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 4s 74us/sample - loss: 1.3803 - accuracy: 0.5036 - val_loss: 1.4607 - val_accuracy: 0.4879\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 1.3680 - accuracy: 0.5074 - val_loss: 1.4668 - val_accuracy: 0.4772\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 4s 74us/sample - loss: 1.3539 - accuracy: 0.5138 - val_loss: 1.4795 - val_accuracy: 0.4761\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 4s 72us/sample - loss: 1.3434 - accuracy: 0.5194 - val_loss: 1.5545 - val_accuracy: 0.4499\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 4s 72us/sample - loss: 1.3318 - accuracy: 0.5248 - val_loss: 1.5267 - val_accuracy: 0.4621\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 1.3224 - accuracy: 0.5263 - val_loss: 1.4777 - val_accuracy: 0.4746\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 4s 75us/sample - loss: 1.3105 - accuracy: 0.5327 - val_loss: 1.4992 - val_accuracy: 0.4764\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 74us/sample - loss: 1.3022 - accuracy: 0.5317 - val_loss: 1.4812 - val_accuracy: 0.4823\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 76us/sample - loss: 1.2900 - accuracy: 0.5384 - val_loss: 1.5329 - val_accuracy: 0.4641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f991e72e650>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our baseline model for this lab.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_shape=(3072,)))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Notice that you can reshape the data for an MLP inside the fit call without changing it globally!\n",
    "model.fit(x_train.reshape(50000, 3072), y_train, epochs=20, batch_size=64, validation_data=(x_test.reshape(10000, 3072), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 215,652\n",
      "Trainable params: 215,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 21s 419us/sample - loss: 4.2360 - accuracy: 0.0519 - val_loss: 4.0565 - val_accuracy: 0.0712\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 4s 89us/sample - loss: 3.8587 - accuracy: 0.1056 - val_loss: 3.7702 - val_accuracy: 0.1221\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 3.6903 - accuracy: 0.1321 - val_loss: 3.8691 - val_accuracy: 0.1156\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 4s 83us/sample - loss: 3.5919 - accuracy: 0.1470 - val_loss: 3.6086 - val_accuracy: 0.1478\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 5s 91us/sample - loss: 3.5163 - accuracy: 0.1612 - val_loss: 3.6022 - val_accuracy: 0.1445\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 5s 92us/sample - loss: 3.4558 - accuracy: 0.1724 - val_loss: 3.5839 - val_accuracy: 0.1512\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 5s 93us/sample - loss: 3.4006 - accuracy: 0.1845 - val_loss: 3.5782 - val_accuracy: 0.1629\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 5s 91us/sample - loss: 3.3646 - accuracy: 0.1903 - val_loss: 3.4798 - val_accuracy: 0.1765\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 5s 92us/sample - loss: 3.3336 - accuracy: 0.1934 - val_loss: 3.5255 - val_accuracy: 0.1627\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 5s 90us/sample - loss: 3.3035 - accuracy: 0.1975 - val_loss: 3.4797 - val_accuracy: 0.1776\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 5s 93us/sample - loss: 3.2808 - accuracy: 0.2021 - val_loss: 3.3868 - val_accuracy: 0.1899\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 5s 92us/sample - loss: 3.2551 - accuracy: 0.2064 - val_loss: 3.4181 - val_accuracy: 0.1867\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 5s 92us/sample - loss: 3.2341 - accuracy: 0.2124 - val_loss: 3.4187 - val_accuracy: 0.1867\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 5s 91us/sample - loss: 3.2144 - accuracy: 0.2141 - val_loss: 3.5332 - val_accuracy: 0.1720\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 5s 93us/sample - loss: 3.2007 - accuracy: 0.2172 - val_loss: 3.4220 - val_accuracy: 0.1925\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 5s 91us/sample - loss: 3.1798 - accuracy: 0.2213 - val_loss: 3.3862 - val_accuracy: 0.1931\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 89us/sample - loss: 3.1697 - accuracy: 0.2228 - val_loss: 3.5113 - val_accuracy: 0.1809\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 5s 94us/sample - loss: 3.1502 - accuracy: 0.2290 - val_loss: 3.4283 - val_accuracy: 0.1874\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 5s 96us/sample - loss: 3.1426 - accuracy: 0.2284 - val_loss: 3.4200 - val_accuracy: 0.1886\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 5s 98us/sample - loss: 3.1307 - accuracy: 0.2285 - val_loss: 3.4140 - val_accuracy: 0.1984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98f80efdd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same for CIFAR-100.\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x100_train.reshape(50000, 3072), y100_train, epochs=20, batch_size=64, validation_data=(x100_test.reshape(10000, 3072), y100_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               410112    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 443,882\n",
      "Trainable params: 443,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 117s 2ms/sample - loss: 1.5862 - accuracy: 0.4169 - val_loss: 1.3045 - val_accuracy: 0.5263\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 1.2311 - accuracy: 0.5609 - val_loss: 1.0766 - val_accuracy: 0.6200\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 144s 3ms/sample - loss: 1.0549 - accuracy: 0.6277 - val_loss: 0.9562 - val_accuracy: 0.6655\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 146s 3ms/sample - loss: 0.9352 - accuracy: 0.6714 - val_loss: 0.9295 - val_accuracy: 0.6810\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 108s 2ms/sample - loss: 0.8556 - accuracy: 0.7004 - val_loss: 0.8434 - val_accuracy: 0.7045\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.7832 - accuracy: 0.7258 - val_loss: 0.8025 - val_accuracy: 0.7187\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.7294 - accuracy: 0.7442 - val_loss: 0.7965 - val_accuracy: 0.7263\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.6821 - accuracy: 0.7594 - val_loss: 0.7825 - val_accuracy: 0.7266\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.6455 - accuracy: 0.7719 - val_loss: 0.7756 - val_accuracy: 0.7336\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.6020 - accuracy: 0.7871 - val_loss: 0.7656 - val_accuracy: 0.7445\n"
     ]
    }
   ],
   "source": [
    "# Create the CIFAR-10 CNN baseline here.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))       \n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(x_train, y_train,\n",
    "            batch_size = 64,\n",
    "            epochs = 10,      \n",
    "            validation_data=(x_test, y_test))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               410112    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 490,052\n",
      "Trainable params: 490,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 4.0141 - accuracy: 0.0844 - val_loss: 3.4677 - val_accuracy: 0.1821\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 3.3984 - accuracy: 0.1850 - val_loss: 3.1336 - val_accuracy: 0.2330\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 3.0951 - accuracy: 0.2403 - val_loss: 2.8827 - val_accuracy: 0.2855\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 114s 2ms/sample - loss: 2.8814 - accuracy: 0.2817 - val_loss: 2.7168 - val_accuracy: 0.3215\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 113s 2ms/sample - loss: 2.7250 - accuracy: 0.3130 - val_loss: 2.6351 - val_accuracy: 0.3338\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 2.5841 - accuracy: 0.3400 - val_loss: 2.5249 - val_accuracy: 0.3598\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 2.4823 - accuracy: 0.3585 - val_loss: 2.4879 - val_accuracy: 0.3665\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 2.3889 - accuracy: 0.3812 - val_loss: 2.4487 - val_accuracy: 0.3761\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 116s 2ms/sample - loss: 2.2954 - accuracy: 0.3969 - val_loss: 2.4066 - val_accuracy: 0.3856\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 114s 2ms/sample - loss: 2.2247 - accuracy: 0.4135 - val_loss: 2.3767 - val_accuracy: 0.3917\n"
     ]
    }
   ],
   "source": [
    "# Create the CIFAR-100 CNN baseline here.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))       \n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(x100_train, y100_train,\n",
    "            batch_size = 64,\n",
    "            epochs = 10,      \n",
    "            validation_data=(x100_test, y100_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 937,418\n",
      "Trainable params: 937,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 361s 7ms/sample - loss: 1.4882 - accuracy: 0.4588 - val_loss: 1.1920 - val_accuracy: 0.5758\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 376s 8ms/sample - loss: 1.0391 - accuracy: 0.6338 - val_loss: 0.9335 - val_accuracy: 0.6705\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 360s 7ms/sample - loss: 0.8642 - accuracy: 0.6983 - val_loss: 0.8178 - val_accuracy: 0.7165\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 284s 6ms/sample - loss: 0.7638 - accuracy: 0.7344 - val_loss: 0.7751 - val_accuracy: 0.7315\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 284s 6ms/sample - loss: 0.6762 - accuracy: 0.7634 - val_loss: 0.7508 - val_accuracy: 0.7389\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 282s 6ms/sample - loss: 0.6097 - accuracy: 0.7874 - val_loss: 0.7684 - val_accuracy: 0.7365\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 279s 6ms/sample - loss: 0.5488 - accuracy: 0.8075 - val_loss: 0.7077 - val_accuracy: 0.7666\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 346s 7ms/sample - loss: 0.5027 - accuracy: 0.8229 - val_loss: 0.7025 - val_accuracy: 0.7693\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 327s 7ms/sample - loss: 0.4553 - accuracy: 0.8383 - val_loss: 0.7530 - val_accuracy: 0.7559\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 325s 7ms/sample - loss: 0.4103 - accuracy: 0.8536 - val_loss: 0.7400 - val_accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "# Change the Convolutional layers to 64 filters for CIFAR-10.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))       \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(x_train, y_train,\n",
    "            batch_size = 64,\n",
    "            epochs = 10,      \n",
    "            validation_data=(x_test, y_test))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 12, 12, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 10, 10, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 217,850\n",
      "Trainable params: 217,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 1.6637 - accuracy: 0.3842 - val_loss: 1.4013 - val_accuracy: 0.4949\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.3392 - accuracy: 0.5134 - val_loss: 1.1890 - val_accuracy: 0.5785\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.2090 - accuracy: 0.5699 - val_loss: 1.2080 - val_accuracy: 0.5783\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.1162 - accuracy: 0.6064 - val_loss: 1.0911 - val_accuracy: 0.6133\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.0442 - accuracy: 0.6329 - val_loss: 1.0035 - val_accuracy: 0.6474\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.9936 - accuracy: 0.6495 - val_loss: 1.1144 - val_accuracy: 0.6134\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 61s 1ms/sample - loss: 0.9432 - accuracy: 0.6686 - val_loss: 0.9235 - val_accuracy: 0.6723\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.8987 - accuracy: 0.6844 - val_loss: 0.9032 - val_accuracy: 0.6851\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.8620 - accuracy: 0.6942 - val_loss: 0.8780 - val_accuracy: 0.6997\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 61s 1ms/sample - loss: 0.8321 - accuracy: 0.7055 - val_loss: 0.9097 - val_accuracy: 0.6791\n"
     ]
    }
   ],
   "source": [
    "# Change the Convolutional layers to 16 filters for CIFAR-10.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))       \n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(x_train, y_train,\n",
    "            batch_size = 64,\n",
    "            epochs = 10,      \n",
    "            validation_data=(x_test, y_test))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 9,471,466\n",
      "Trainable params: 9,471,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 265s 5ms/sample - loss: 1.5270 - accuracy: 0.4462 - val_loss: 1.2352 - val_accuracy: 0.5627\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 263s 5ms/sample - loss: 1.1179 - accuracy: 0.6047 - val_loss: 1.0172 - val_accuracy: 0.6424\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 263s 5ms/sample - loss: 0.9194 - accuracy: 0.6743 - val_loss: 0.9279 - val_accuracy: 0.6790\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 269s 5ms/sample - loss: 0.7687 - accuracy: 0.7271 - val_loss: 0.9216 - val_accuracy: 0.6799\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 268s 5ms/sample - loss: 0.6291 - accuracy: 0.7788 - val_loss: 0.9313 - val_accuracy: 0.6900\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 276s 6ms/sample - loss: 0.5002 - accuracy: 0.8241 - val_loss: 0.9455 - val_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 270s 5ms/sample - loss: 0.3904 - accuracy: 0.8623 - val_loss: 1.0731 - val_accuracy: 0.6946\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 269s 5ms/sample - loss: 0.3149 - accuracy: 0.8870 - val_loss: 1.1543 - val_accuracy: 0.6933\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 270s 5ms/sample - loss: 0.2598 - accuracy: 0.9081 - val_loss: 1.2527 - val_accuracy: 0.6848\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 271s 5ms/sample - loss: 0.2219 - accuracy: 0.9222 - val_loss: 1.2381 - val_accuracy: 0.6908\n"
     ]
    }
   ],
   "source": [
    "# Remove the Max Pooling Layers for CIFAR-10.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))       \n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(x_train, y_train,\n",
    "            batch_size = 64,\n",
    "            epochs = 10,      \n",
    "            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 9,517,636\n",
      "Trainable params: 9,517,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 277s 6ms/sample - loss: 4.0646 - accuracy: 0.0804 - val_loss: 3.5979 - val_accuracy: 0.1616\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 251s 5ms/sample - loss: 3.4984 - accuracy: 0.1694 - val_loss: 3.2174 - val_accuracy: 0.2281\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 256s 5ms/sample - loss: 3.1489 - accuracy: 0.2343 - val_loss: 2.9783 - val_accuracy: 0.2763\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 266s 5ms/sample - loss: 2.8381 - accuracy: 0.2945 - val_loss: 2.8987 - val_accuracy: 0.2920\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 265s 5ms/sample - loss: 2.5372 - accuracy: 0.3497 - val_loss: 2.8097 - val_accuracy: 0.3106\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 262s 5ms/sample - loss: 2.2215 - accuracy: 0.4153 - val_loss: 2.8287 - val_accuracy: 0.3133\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 261s 5ms/sample - loss: 1.8712 - accuracy: 0.4938 - val_loss: 2.9234 - val_accuracy: 0.3106\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 263s 5ms/sample - loss: 1.5465 - accuracy: 0.5675 - val_loss: 3.0815 - val_accuracy: 0.3066\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 262s 5ms/sample - loss: 1.2474 - accuracy: 0.6407 - val_loss: 3.3203 - val_accuracy: 0.2967\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 264s 5ms/sample - loss: 1.0330 - accuracy: 0.6973 - val_loss: 3.5263 - val_accuracy: 0.2960\n"
     ]
    }
   ],
   "source": [
    "# Remove the Max Pooling Layers for CIFAR-100.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))       \n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(x100_train, y100_train,\n",
    "            batch_size = 64,\n",
    "            epochs = 10,      \n",
    "            validation_data=(x100_test, y100_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 782 steps, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "782/782 [==============================] - 97s 124ms/step - loss: 1.8367 - accuracy: 0.3264 - val_loss: 1.3982 - val_accuracy: 0.4920\n",
      "Epoch 2/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 1.4202 - accuracy: 0.4860 - val_loss: 1.1817 - val_accuracy: 0.5753\n",
      "Epoch 3/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 1.2574 - accuracy: 0.5479 - val_loss: 1.0560 - val_accuracy: 0.6257\n",
      "Epoch 4/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 1.1465 - accuracy: 0.5897 - val_loss: 1.0090 - val_accuracy: 0.6400\n",
      "Epoch 5/40\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 1.0788 - accuracy: 0.6171 - val_loss: 0.8934 - val_accuracy: 0.6844\n",
      "Epoch 6/40\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 1.0210 - accuracy: 0.6411 - val_loss: 0.9206 - val_accuracy: 0.6845\n",
      "Epoch 7/40\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.9729 - accuracy: 0.6567 - val_loss: 0.8445 - val_accuracy: 0.7056\n",
      "Epoch 8/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.9255 - accuracy: 0.6709 - val_loss: 0.8137 - val_accuracy: 0.7244\n",
      "Epoch 9/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8906 - accuracy: 0.6871 - val_loss: 0.7845 - val_accuracy: 0.7278\n",
      "Epoch 10/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.8680 - accuracy: 0.6975 - val_loss: 0.7315 - val_accuracy: 0.7473\n",
      "Epoch 11/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8390 - accuracy: 0.7057 - val_loss: 0.7410 - val_accuracy: 0.7430\n",
      "Epoch 12/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8199 - accuracy: 0.7134 - val_loss: 0.7189 - val_accuracy: 0.7539\n",
      "Epoch 13/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8041 - accuracy: 0.7187 - val_loss: 0.6889 - val_accuracy: 0.7559\n",
      "Epoch 14/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7907 - accuracy: 0.7232 - val_loss: 0.7036 - val_accuracy: 0.7570\n",
      "Epoch 15/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7733 - accuracy: 0.7301 - val_loss: 0.6961 - val_accuracy: 0.7639\n",
      "Epoch 16/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7577 - accuracy: 0.7360 - val_loss: 0.6755 - val_accuracy: 0.7665\n",
      "Epoch 17/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7481 - accuracy: 0.7396 - val_loss: 0.6707 - val_accuracy: 0.7697\n",
      "Epoch 18/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7404 - accuracy: 0.7428 - val_loss: 0.6921 - val_accuracy: 0.7626\n",
      "Epoch 19/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.7260 - accuracy: 0.7470 - val_loss: 0.6605 - val_accuracy: 0.7725\n",
      "Epoch 20/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7199 - accuracy: 0.7474 - val_loss: 0.6993 - val_accuracy: 0.7702\n",
      "Epoch 21/40\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.7055 - accuracy: 0.7546 - val_loss: 0.6479 - val_accuracy: 0.7813\n",
      "Epoch 22/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7063 - accuracy: 0.7553 - val_loss: 0.6354 - val_accuracy: 0.7849\n",
      "Epoch 23/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6957 - accuracy: 0.7588 - val_loss: 0.6297 - val_accuracy: 0.7914\n",
      "Epoch 24/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.6875 - accuracy: 0.7617 - val_loss: 0.6182 - val_accuracy: 0.7890\n",
      "Epoch 25/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6874 - accuracy: 0.7618 - val_loss: 0.6430 - val_accuracy: 0.7819\n",
      "Epoch 26/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6854 - accuracy: 0.7634 - val_loss: 0.6539 - val_accuracy: 0.7850\n",
      "Epoch 27/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6673 - accuracy: 0.7681 - val_loss: 0.6345 - val_accuracy: 0.7842\n",
      "Epoch 28/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6679 - accuracy: 0.7682 - val_loss: 0.6640 - val_accuracy: 0.7793\n",
      "Epoch 29/40\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.6635 - accuracy: 0.7710 - val_loss: 0.6248 - val_accuracy: 0.7853\n",
      "Epoch 30/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.6569 - accuracy: 0.7704 - val_loss: 0.5951 - val_accuracy: 0.8004\n",
      "Epoch 31/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6529 - accuracy: 0.7743 - val_loss: 0.6019 - val_accuracy: 0.7941\n",
      "Epoch 32/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.6504 - accuracy: 0.7753 - val_loss: 0.5859 - val_accuracy: 0.8023\n",
      "Epoch 33/40\n",
      "782/782 [==============================] - 97s 124ms/step - loss: 0.6357 - accuracy: 0.7789 - val_loss: 0.6280 - val_accuracy: 0.7883\n",
      "Epoch 34/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6389 - accuracy: 0.7776 - val_loss: 0.5808 - val_accuracy: 0.8025\n",
      "Epoch 35/40\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.6341 - accuracy: 0.7794 - val_loss: 0.6062 - val_accuracy: 0.7993\n",
      "Epoch 36/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6284 - accuracy: 0.7820 - val_loss: 0.5900 - val_accuracy: 0.8021\n",
      "Epoch 37/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6234 - accuracy: 0.7864 - val_loss: 0.5830 - val_accuracy: 0.8073\n",
      "Epoch 38/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6207 - accuracy: 0.7839 - val_loss: 0.5917 - val_accuracy: 0.8010\n",
      "Epoch 39/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6223 - accuracy: 0.7854 - val_loss: 0.5780 - val_accuracy: 0.8069\n",
      "Epoch 40/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6154 - accuracy: 0.7872 - val_loss: 0.6042 - val_accuracy: 0.7946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e8a7b1508>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Augmentation.\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 40\n",
    "data_augmentation = True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0., \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False, \n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    model.fit(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 798s 20ms/sample - loss: 0.2837 - accuracy: 0.9003 - val_loss: 0.4043 - val_accuracy: 0.8999\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 703s 18ms/sample - loss: 0.2093 - accuracy: 0.9194 - val_loss: 0.4825 - val_accuracy: 0.8715\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 901s 23ms/sample - loss: 0.1708 - accuracy: 0.9341 - val_loss: 0.2555 - val_accuracy: 0.9088\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 957s 24ms/sample - loss: 0.1460 - accuracy: 0.9439 - val_loss: 0.1696 - val_accuracy: 0.9334\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 880s 22ms/sample - loss: 0.1289 - accuracy: 0.9509 - val_loss: 0.1831 - val_accuracy: 0.9315\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 717s 18ms/sample - loss: 0.1162 - accuracy: 0.9559 - val_loss: 0.1590 - val_accuracy: 0.9411\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 786s 20ms/sample - loss: 0.1045 - accuracy: 0.9600 - val_loss: 0.1510 - val_accuracy: 0.9433\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 687s 17ms/sample - loss: 0.0948 - accuracy: 0.9641 - val_loss: 0.1323 - val_accuracy: 0.9501\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 684s 17ms/sample - loss: 0.0883 - accuracy: 0.9667 - val_loss: 0.1489 - val_accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 684s 17ms/sample - loss: 0.0817 - accuracy: 0.9692 - val_loss: 0.1568 - val_accuracy: 0.9435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f53800e4050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is our CIFAR-10 CNN ResNet.\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3), name='img')\n",
    "x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = Conv2D(64, 3, activation='relu')(x)\n",
    "block_1_output = MaxPooling2D(3)(x)\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_2_output = tf.keras.layers.add([x, block_1_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_3_output = tf.keras.layers.add([x, block_2_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_3_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_4_output = tf.keras.layers.add([x, block_3_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_4_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_5_output = tf.keras.layers.add([x, block_4_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_5_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_6_output = tf.keras.layers.add([x, block_5_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_6_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_7_output = tf.keras.layers.add([x, block_6_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_7_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_8_output = tf.keras.layers.add([x, block_7_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_8_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_9_output = tf.keras.layers.add([x, block_8_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_9_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_10_output = tf.keras.layers.add([x, block_9_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_10_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_11_output = tf.keras.layers.add([x, block_10_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_11_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_12_output = tf.keras.layers.add([x, block_11_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_12_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_13_output = tf.keras.layers.add([x, block_12_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_13_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_14_output = tf.keras.layers.add([x, block_13_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_14_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_15_output = tf.keras.layers.add([x, block_14_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_15_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_16_output = tf.keras.layers.add([x, block_15_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_16_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_17_output = tf.keras.layers.add([x, block_16_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_17_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_18_output = tf.keras.layers.add([x, block_17_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_18_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_19_output = tf.keras.layers.add([x, block_18_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_19_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_20_output = tf.keras.layers.add([x, block_19_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu')(block_20_output)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name='resnet')\n",
    "\n",
    "\n",
    "model.compile(Adam(amsgrad=True), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=256,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 776s 19ms/sample - loss: 0.0561 - accuracy: 0.9900 - val_loss: 0.0557 - val_accuracy: 0.9900\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 708s 18ms/sample - loss: 0.0545 - accuracy: 0.9900 - val_loss: 0.0542 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 674s 17ms/sample - loss: 0.0526 - accuracy: 0.9900 - val_loss: 0.0534 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 680s 17ms/sample - loss: 0.0505 - accuracy: 0.9900 - val_loss: 0.0511 - val_accuracy: 0.9900\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 682s 17ms/sample - loss: 0.0477 - accuracy: 0.9900 - val_loss: 0.0480 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 680s 17ms/sample - loss: 0.0448 - accuracy: 0.9900 - val_loss: 0.0469 - val_accuracy: 0.9900\n",
      "Epoch 7/10\n",
      " 2048/40000 [>.............................] - ETA: 10:14 - loss: 0.0430 - accuracy: 0.9902"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4ca9bf5d9a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m           validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the CIFAR-100 CNN ResNet.\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3), name='img')\n",
    "x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = Conv2D(64, 3, activation='relu')(x)\n",
    "block_1_output = MaxPooling2D(3)(x)\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_2_output = tf.keras.layers.add([x, block_1_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_3_output = tf.keras.layers.add([x, block_2_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_3_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_4_output = tf.keras.layers.add([x, block_3_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_4_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_5_output = tf.keras.layers.add([x, block_4_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_5_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_6_output = tf.keras.layers.add([x, block_5_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_6_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_7_output = tf.keras.layers.add([x, block_6_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_7_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_8_output = tf.keras.layers.add([x, block_7_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_8_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_9_output = tf.keras.layers.add([x, block_8_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_9_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_10_output = tf.keras.layers.add([x, block_9_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_10_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_11_output = tf.keras.layers.add([x, block_10_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_11_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_12_output = tf.keras.layers.add([x, block_11_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_12_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_13_output = tf.keras.layers.add([x, block_12_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_13_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_14_output = tf.keras.layers.add([x, block_13_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_14_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_15_output = tf.keras.layers.add([x, block_14_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_15_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_16_output = tf.keras.layers.add([x, block_15_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_16_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_17_output = tf.keras.layers.add([x, block_16_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_17_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_18_output = tf.keras.layers.add([x, block_17_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_18_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_19_output = tf.keras.layers.add([x, block_18_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_19_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_20_output = tf.keras.layers.add([x, block_19_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu')(block_20_output)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name='resnet')\n",
    "\n",
    "\n",
    "model.compile(Adam(amsgrad=True), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x100_train, y100_train,\n",
    "          batch_size=256,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 2500 steps, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "2500/2500 [==============================] - 951s 381ms/step - loss: 4.1914 - accuracy: 0.0590 - val_loss: 3.7136 - val_accuracy: 0.1341\n",
      "Epoch 2/40\n",
      "2500/2500 [==============================] - 943s 377ms/step - loss: 3.6236 - accuracy: 0.1438 - val_loss: 3.2449 - val_accuracy: 0.2208\n",
      "Epoch 3/40\n",
      "2500/2500 [==============================] - 942s 377ms/step - loss: 3.3383 - accuracy: 0.1943 - val_loss: 2.9571 - val_accuracy: 0.2765\n",
      "Epoch 4/40\n",
      "2500/2500 [==============================] - 943s 377ms/step - loss: 3.1482 - accuracy: 0.2316 - val_loss: 2.8616 - val_accuracy: 0.2918\n",
      "Epoch 5/40\n",
      "2500/2500 [==============================] - 943s 377ms/step - loss: 3.0214 - accuracy: 0.2541 - val_loss: 2.7682 - val_accuracy: 0.3075\n",
      "Epoch 6/40\n",
      "2500/2500 [==============================] - 958s 383ms/step - loss: 2.9424 - accuracy: 0.2709 - val_loss: 2.6235 - val_accuracy: 0.3438\n",
      "Epoch 7/40\n",
      "2500/2500 [==============================] - 1037s 415ms/step - loss: 2.8652 - accuracy: 0.2859 - val_loss: 2.5855 - val_accuracy: 0.3463\n",
      "Epoch 8/40\n",
      "2500/2500 [==============================] - 951s 380ms/step - loss: 2.8155 - accuracy: 0.2980 - val_loss: 2.5996 - val_accuracy: 0.3480\n",
      "Epoch 9/40\n",
      "2500/2500 [==============================] - 936s 375ms/step - loss: 2.7637 - accuracy: 0.3062 - val_loss: 2.5334 - val_accuracy: 0.3570\n",
      "Epoch 10/40\n",
      "2500/2500 [==============================] - 936s 374ms/step - loss: 2.7240 - accuracy: 0.3138 - val_loss: 2.4738 - val_accuracy: 0.3640\n",
      "Epoch 11/40\n",
      "2500/2500 [==============================] - 937s 375ms/step - loss: 2.7032 - accuracy: 0.3194 - val_loss: 2.5205 - val_accuracy: 0.3592\n",
      "Epoch 12/40\n",
      "2500/2500 [==============================] - 937s 375ms/step - loss: 2.6894 - accuracy: 0.3251 - val_loss: 2.5227 - val_accuracy: 0.3592\n",
      "Epoch 13/40\n",
      "2500/2500 [==============================] - 937s 375ms/step - loss: 2.6914 - accuracy: 0.3217 - val_loss: 2.4522 - val_accuracy: 0.3734\n",
      "Epoch 14/40\n",
      "2500/2500 [==============================] - 938s 375ms/step - loss: 2.6722 - accuracy: 0.3250 - val_loss: 2.5109 - val_accuracy: 0.3658\n",
      "Epoch 15/40\n",
      "2500/2500 [==============================] - 954s 382ms/step - loss: 2.6615 - accuracy: 0.3280 - val_loss: 2.4452 - val_accuracy: 0.3797\n",
      "Epoch 16/40\n",
      "2500/2500 [==============================] - 957s 383ms/step - loss: 2.6510 - accuracy: 0.3296 - val_loss: 2.4171 - val_accuracy: 0.3818\n",
      "Epoch 17/40\n",
      "2500/2500 [==============================] - 967s 387ms/step - loss: 2.6363 - accuracy: 0.3325 - val_loss: 2.4610 - val_accuracy: 0.3687\n",
      "Epoch 18/40\n",
      "1335/2500 [===============>..............] - ETA: 7:04 - loss: 2.6165 - accuracy: 0.3381"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-efd5c740347c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m                         batch_size=batch_size),\n\u001b[1;32m     68\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                         validation_data=(x100_test, y100_test))\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx100_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my100_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create your own CNN that rivals a CNN ResNet for CIFAR-100.\n",
    "batch_size = 20\n",
    "num_classes = 100\n",
    "epochs = 40\n",
    "data_augmentation = True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(120, (3, 3), padding='same', input_shape=x100_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(120, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(120, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(120, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x100_train, y100_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x100_test, y100_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0., \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False, \n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    datagen.fit(x100_train)\n",
    "\n",
    "    model.fit(datagen.flow(x100_train, y100_train,\n",
    "                        batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x100_test, y100_test))\n",
    "\n",
    "scores = model.evaluate(x100_test, y100_test, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
